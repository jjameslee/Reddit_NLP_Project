{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Reddit NLP - Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushshift API\n",
    "\n",
    "Pushshift is a service that archives and indexes Reddit at regular intervals. It allows for higher-level search functionality and querying for Reddit comments and submissions, facilitating data collection for analysis and modeling. It leverages the requests library to return a json response that can then be parsed for the data of interest.\n",
    "\n",
    "Resources:\n",
    "\n",
    "* Pushshift Endpoints: https://pushshift.io/\n",
    "* Pushshift Documentation: https://github.com/pushshift/api\n",
    "* Pushshift Subreddit: https://www.reddit.com/r/pushshift/comments/89pxra/pushshift_api_with_large_amounts_of_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import requests, json, time, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the base query syntax:\n",
    "Setting the query url to the pushshift api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1= 'https://api.pushshift.io/reddit/search/comment/?subreddit=BlackPink'\n",
    "url_2= 'https://api.pushshift.io/reddit/search/comment/?subreddit=bangtan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'sort':'desc',\n",
    "          'size':10,\n",
    "         }\n",
    "\n",
    "response_1 = requests.get(url_1, params=params)\n",
    "response_2 = requests.get(url_2, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status code returned from the server is 200, meaning the query was accepted and there aren't any connection issues. Checking length of the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response_1.json()['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the length is 10. This is the 10 comments pulled from the subreddit. Below is the first response pulled from the 'BlackPink' subreddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'iFappa',\n",
       " 'author_flair_background_color': None,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'author_flair_template_id': None,\n",
       " 'author_flair_text': None,\n",
       " 'author_flair_text_color': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'author_fullname': 't2_qb71o',\n",
       " 'author_patreon_flair': False,\n",
       " 'body': \"You can expect some of them to have a more mellowed out Rock that leans more towards RnB. There are a ton of ways to do rock. Nonetheless, I'm very excited for the release. \",\n",
       " 'created_utc': 1554339044,\n",
       " 'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       " 'id': 'ek2gz36',\n",
       " 'is_submitter': False,\n",
       " 'link_id': 't3_b95tgv',\n",
       " 'no_follow': True,\n",
       " 'parent_id': 't1_ek2exc0',\n",
       " 'permalink': '/r/BlackPink/comments/b95tgv/190403_blackpink_kill_this_love_album_song/ek2gz36/',\n",
       " 'retrieved_on': 1554339045,\n",
       " 'score': 1,\n",
       " 'send_replies': True,\n",
       " 'stickied': False,\n",
       " 'subreddit': 'BlackPink',\n",
       " 'subreddit_id': 't5_3f8po'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1.json()['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Reddit and saving raw data in .json format:\n",
    "Writing a function for creating a logfile and formatting file names with a unique timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_format_log(file_path, \n",
    "                        logfile = './assets/file_log.txt', \n",
    "                        now = round(time.time()), \n",
    "                        file_description = None): \n",
    "   \n",
    "    try:\n",
    "        ext = re.search('(?<!^)(?<!\\.)\\.(?!\\.)', file_path).start() \n",
    "    except:\n",
    "        raise NameError('Please enter a relative path with a file extension.') \n",
    "    \n",
    "    stamp = re.search('(?<!^)(?<!\\.)[a-z]+_[a-z]+(?=\\.)', file_path).start()\n",
    "    formatted_name = f'{file_path[:stamp]}{now}_{file_path[stamp:]}'  \n",
    "    if not file_description:\n",
    "        file_description = f'Pull: {time.asctime(time.gmtime(now))}'\n",
    "    with open(logfile, 'a+') as f:\n",
    "        f.write(f'{formatted_name}: {file_description}\\n')\n",
    "    return formatted_name, now, file_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a function for collecting comments and parsing into a dataframe with the features of interest, saving out the raw data for each pull. Request loop inspired: [(Source)](https://www.reddit.com/r/pushshift/comments/89pxra/pushshift_api_with_large_amounts_of_data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_query(url, n_samples, before=None, after=None):\n",
    "    last_comment = round(time.time())\n",
    "    comment_list = []\n",
    "    \n",
    "    run = 1\n",
    "    while len(comment_list) < n_samples:\n",
    "        \n",
    "        try:\n",
    "            print(f'Starting query {run}')\n",
    "            \n",
    "            params = {\n",
    "              'sort':'desc',\n",
    "              'size':1000,\n",
    "              'before':last_comment-1,\n",
    "              'after':after,\n",
    "             }\n",
    "                \n",
    "            response = requests.get(url, params = params)\n",
    "            posts = response.json()['data']\n",
    "            \n",
    "            if len(posts) == 0:\n",
    "                last_comment = last_comment\n",
    "            else:\n",
    "                last_comment = posts[-1]['created_utc']\n",
    "                comment_list.extend(posts)\n",
    "                timestamp = posts[-1]['created_utc']\n",
    "                time.sleep(1) \n",
    "                run += 1\n",
    "        except:\n",
    "            if response.status_code != 200:\n",
    "                return f'Check status. Error code: {response.status_code}'\n",
    "            else:\n",
    "                return 'Error. Pull not completed.'\n",
    "    \n",
    "    formatted_name, now, file_description = filename_format_log(file_path =f'./data/raw_submissions.json', now=timestamp)\n",
    "    with open(formatted_name, 'w+') as f:\n",
    "        json.dump(comment_list, f)\n",
    "    \n",
    "    print(f'Saved and completed query and returned {len(comment_list)} comments.')\n",
    "    print(f'Reddit text is ready for processing.')\n",
    "    return print(f'Last timestamp was {timestamp}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the query function, I will collect 10k comments from the 'Blackpink' subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query 1\n",
      "Starting query 2\n",
      "Starting query 3\n",
      "Starting query 4\n",
      "Starting query 5\n",
      "Starting query 6\n",
      "Starting query 7\n",
      "Starting query 8\n",
      "Starting query 9\n",
      "Starting query 10\n",
      "Saved and completed query and returned 10000 comments.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1549943009.\n"
     ]
    }
   ],
   "source": [
    "# reddit_query(url=url_1,\n",
    "#              n_samples=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the query function, I will collect 10k comments from the 'bangtan' subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query 1\n",
      "Starting query 2\n",
      "Starting query 3\n",
      "Starting query 4\n",
      "Starting query 5\n",
      "Starting query 6\n",
      "Starting query 7\n",
      "Starting query 8\n",
      "Starting query 9\n",
      "Starting query 10\n",
      "Saved and completed query and returned 10000 comments.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1553656065.\n"
     ]
    }
   ],
   "source": [
    "# reddit_query(url=url_2,\n",
    "#              n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the Blackpink samples as a .json file and confirming the correct amount of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/1549943009_raw_submissions.json', 'r') as f:\n",
    "    bp_sample_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bp_sample_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the Bts (bangtan) samples as a .json file and confirming the correct amount of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/1553656065_raw_submissions.json', 'r') as f:\n",
    "    bts_sample_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bts_sample_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the json file into a dataframe containing the features of interest. The 2 keys of interest are 'body', which contains the texts of each comments, and 'subreddit', which contains whether or not the comment belongs to the 'BlackPink' subreddit. \n",
    "I will also change the column name from 'subreddit' to 'blackpink'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_parse(sample):\n",
    "    \n",
    "    col_list = [\n",
    "                'body',\n",
    "                'subreddit'\n",
    "                ]\n",
    "    \n",
    "    comments_df = pd.DataFrame(sample)\n",
    "    comments_df = comments_df[col_list]\n",
    "    \n",
    "    comments_df.rename(columns={'subreddit':'blackpink'}, inplace=True)\n",
    "    comments_df['blackpink'] = comments_df['blackpink'].map({'bangtan':0, 'BlackPink':1})\n",
    "    \n",
    "    col_order = [\n",
    "                 'body',\n",
    "                 'blackpink'\n",
    "                ]\n",
    "\n",
    "    return comments_df[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_comments = reddit_parse(bts_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>blackpink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry, Photoshop crashed before I could make t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's this? Smiles? I can finally go to bed h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I get my DVD tomorrow so I can let you know if...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just read Ep 15 of Webtoon. I AM NOT OKAY!!!!!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That is amazing 😂 your manager is awesome!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  blackpink\n",
       "0  Sorry, Photoshop crashed before I could make t...          0\n",
       "1  What's this? Smiles? I can finally go to bed h...          0\n",
       "2  I get my DVD tomorrow so I can let you know if...          0\n",
       "3  Just read Ep 15 of Webtoon. I AM NOT OKAY!!!!!...          0\n",
       "4        That is amazing 😂 your manager is awesome!           0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bts_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the shape of the dataframe to ensure correct transformation. I will also delete duplicate comments from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bts_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_comments.drop_duplicates(inplace=True)\n",
    "bts_comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_comments = reddit_parse(bp_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>blackpink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Tickets when?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>I would have to go about 10 miles.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>EU they had 4 ticket max I think.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Pretty much its if you own a car you go. I was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>ps y’all ever went to a concert by urself ? i ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  blackpink\n",
       "9995                                      Tickets when?          1\n",
       "9996                I would have to go about 10 miles.           1\n",
       "9997                  EU they had 4 ticket max I think.          1\n",
       "9998  Pretty much its if you own a car you go. I was...          1\n",
       "9999  ps y’all ever went to a concert by urself ? i ...          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_comments.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_comments.drop_duplicates(inplace=True)\n",
    "bp_comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we parsed both json files into their respective dataframes, we will merge to two seperate dataframes into a combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_bts_df = pd.concat([bp_comments,bts_comments], ignore_index=True, sort=False)\n",
    "bp_bts_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>blackpink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is something I can get behind and appreci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hold the fuck up?! Rock songs? I'm considering...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What time and date is this in PDT?\\n\\n0 AM is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is there a list? Last year I remember they str...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a blink I'll wait till mv dropped. Then I'l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  blackpink\n",
       "0  This is something I can get behind and appreci...          1\n",
       "1  Hold the fuck up?! Rock songs? I'm considering...          1\n",
       "2  What time and date is this in PDT?\\n\\n0 AM is ...          1\n",
       "3  Is there a list? Last year I remember they str...          1\n",
       "4  As a blink I'll wait till mv dropped. Then I'l...          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_bts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the original 20k comments we pulled from the 2 subreddits, we have 19,451 total comments left. 549 comments were removed due to being duplicates. Checking the class balance, we can see that they are still balanced for the most part. Thankfully, there are no nulls so we can proceed with our EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19451, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_bts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19451 entries, 0 to 19450\n",
      "Data columns (total 2 columns):\n",
      "body         19451 non-null object\n",
      "blackpink    19451 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 304.0+ KB\n"
     ]
    }
   ],
   "source": [
    "bp_bts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body         0\n",
       "blackpink    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_bts_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.504807\n",
       "1    0.495193\n",
       "Name: blackpink, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_bts_df['blackpink'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using regex to substitute any one or more white-spaces to a regular one white-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_bts_df['body'] = bp_bts_df.body.map(lambda x :re.sub('\\s+', ' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving out the combined dataframe as a csv for data cleaning and exploratory data analysis in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_name, now, file_description = filename_format_log(file_path ='./data/bp_bts_df.csv')\n",
    "bp_bts_df.to_csv(formatted_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>blackpink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8834</th>\n",
       "      <td>Totally agree with this. DDDD/PWF/Whistle or e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  blackpink\n",
       "8834  Totally agree with this. DDDD/PWF/Whistle or e...          1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_bts_df[bp_bts_df.body.str.contains(\"cute concepts wouldn't do well here\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Totally agree with this. DDDD/PWF/Whistle or even Really are definitely the most Western-influenced and would've been the best choices to introduce BP to the US. Also agree that cute concepts wouldn't do well here. \""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_bts_df.body[8834]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Please continue to Notebook 02: Data Cleaning & EDA**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
